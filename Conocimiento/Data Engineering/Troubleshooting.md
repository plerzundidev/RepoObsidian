# üîß Troubleshooting & Debugging - Ayuda Memoria

## 1. üî• Errores Comunes y Soluciones

### Spark / PySpark

| Error | Causa | Soluci√≥n |
| :--- | :--- | :--- |
| `OutOfMemoryError` | Datos no caben en memoria del executor | Aumentar `spark.executor.memory`, reparticionar |
| `Shuffle Spill` | Shuffle desborda a disco | Aumentar particiones, m√°s memoria |
| `Data Skew` | Una partici√≥n tiene mucho m√°s datos | Salting keys, `repartition()` |
| `Task not serializable` | Objeto no serializable en closure | Usar `broadcast()` o extraer a funci√≥n |
| `FileNotFoundException` | Ruta incorrecta o permisos | Verificar path, IAM roles |
| `AnalysisException: cannot resolve` | Columna no existe | Verificar schema con `printSchema()` |
| `Job aborted due to stage failure` | Task fall√≥ m√∫ltiples veces | Revisar logs del executor |

### Debugging Spark
```python
# Ver plan de ejecuci√≥n
df.explain(True)

# Ver schema
df.printSchema()

# Contar particiones
print(f"Particiones: {df.rdd.getNumPartitions()}")

# Verificar tama√±o por partici√≥n
from pyspark.sql.functions import spark_partition_id
df.groupBy(spark_partition_id()).count().show()

# Ver logs del executor
# En Spark UI: http://driver:4040 ‚Üí Stages ‚Üí Task Details
```

---

### SQL

| Error | Causa | Soluci√≥n |
| :--- | :--- | :--- |
| Query lenta | Falta √≠ndice o full table scan | `EXPLAIN ANALYZE`, crear √≠ndices |
| `Deadlock` | Transacciones concurrentes bloquean | Ordenar operaciones, timeout |
| `Connection refused` | BD no accesible | Verificar host, puerto, firewall |
| `Permission denied` | Sin permisos | `GRANT` apropiado |
| `Duplicate key` | Violaci√≥n de constraint | `ON CONFLICT DO UPDATE` |
| `Out of disk space` | Storage lleno | `VACUUM`, limpiar logs, escalar |

### Debugging SQL
```sql
-- Plan de ejecuci√≥n
EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT) 
SELECT * FROM ventas WHERE fecha > '2026-01-01';

-- Conexiones activas
SELECT * FROM pg_stat_activity WHERE state = 'active';

-- Queries lentas
SELECT pid, now() - pg_stat_activity.query_start AS duration, query
FROM pg_stat_activity
WHERE state != 'idle' AND now() - pg_stat_activity.query_start > interval '5 minutes';

-- Tama√±o de tablas
SELECT schemaname, tablename, 
       pg_size_pretty(pg_total_relation_size(schemaname || '.' || tablename)) AS total
FROM pg_tables WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname || '.' || tablename) DESC;

-- Locks activos
SELECT * FROM pg_locks WHERE NOT granted;
```

---

### Airflow

| Error | Causa | Soluci√≥n |
| :--- | :--- | :--- |
| DAG no aparece | Error de sintaxis en DAG file | Revisar logs del scheduler |
| Task stuck en `queued` | Sin workers disponibles | Escalar workers, revisar pools |
| Task stuck en `running` | Zombie task | `airflow tasks clear`, timeout |
| `Import Error` | Dependencia faltante | Instalar en requirements |
| `XCom is too large` | Datos grandes en XCom | Usar paths de archivos, no datos |

```bash
# Debug Airflow
airflow dags list                    # Listar DAGs
airflow tasks test dag_id task_id 2026-02-12  # Ejecutar task en local
airflow dags test dag_id 2026-02-12          # Ejecutar DAG completo
airflow tasks clear dag_id -t task_id -s 2026-02-12  # Limpiar estado
```

---

### Docker / Podman

| Error | Causa | Soluci√≥n |
| :--- | :--- | :--- |
| `Port already in use` | Puerto ocupado | Cambiar puerto, `lsof -i :PORT` |
| `No space left on device` | Disco lleno de im√°genes/volumes | `podman system prune -a` |
| `Cannot connect to daemon` | Daemon no corriendo | `systemctl start docker` |
| `Permission denied` | Sin permisos en socket | Agregar usuario al grupo docker |

```bash
# Debug containers
podman logs -f --tail 100 mi_contenedor
podman inspect mi_contenedor
podman stats                          # Uso de recursos en vivo
podman exec -it mi_contenedor bash    # Entrar al contenedor
```

---

## 2. üîç Metodolog√≠a de Debugging

```mermaid
graph TD
    A["1. Reproducir el error"] --> B["2. Aislar el componente"]
    B --> C["3. Revisar logs"]
    C --> D["4. Verificar datos de entrada"]
    D --> E["5. Probar fix en staging"]
    E --> F["6. Documentar y prevenir"]
```

### Preguntas Clave
1. ¬ø**Cu√°ndo** empez√≥ a fallar? (¬øQu√© cambi√≥?)
2. ¬øEs **intermitente** o constante?
3. ¬øAfecta **todos** los datos o solo un subconjunto?
4. ¬øEl error es de **datos** o de **infraestructura**?
5. ¬øHay **dependencias upstream** que fallaron?

---

## 3. üìä Comandos de Diagn√≥stico R√°pido

```bash
# === Sistema ===
htop                         # CPU y memoria en tiempo real
iostat -x 1                  # I/O de disco
netstat -tlnp                # Puertos abiertos
ss -tlnp                     # Alternativa moderna a netstat
dmesg | tail -50             # Errores del kernel

# === Logs ===
journalctl -u servicio -f    # Logs de systemd
tail -f /var/log/syslog      # Logs del sistema
grep -r "ERROR\|FATAL" /var/log/  # Buscar errores

# === Red ===
curl -v http://api:8080/health   # Verificar conectividad
nslookup hostname                 # Resolver DNS
traceroute hostname               # Ruta de red

# === Archivos ===
wc -l archivo.csv                 # Contar l√≠neas
head -5 archivo.csv               # Primeras 5 l√≠neas
file archivo.dat                  # Detectar formato/encoding
iconv -f ISO-8859-1 -t UTF-8 archivo.csv > utf8.csv  # Fix encoding
```

---

## 4. üìù Template de Postmortem

```markdown
# Postmortem: [T√≠tulo del Incidente]

## Resumen
- **Fecha**: 2026-02-12
- **Duraci√≥n**: 2h 30m
- **Impacto**: Dashboards de ventas sin datos por 2 horas
- **Severidad**: Alta

## Timeline
- 06:00 - Pipeline ejecut√≥ normalmente
- 06:15 - Error en transformaci√≥n por schema change en fuente
- 08:00 - Alerta detectada por equipo
- 08:30 - Fix aplicado, pipeline re-ejecutado
- 08:45 - Datos restaurados

## Causa Ra√≠z
La API de CRM agreg√≥ una nueva columna sin aviso, rompiendo el schema esperado.

## Acciones Correctivas
- [ ] Agregar schema validation en Bronze layer
- [ ] Configurar alertas de schema change
- [ ] Documentar contrato de API con equipo CRM
```

---

## üß≠ Navegaci√≥n

Vuelve al [[√çndice Data Engineering|√çndice]]
Relacionado: [[Observabilidad de Datos|Observabilidad]] | [[Airflow Avanzado|Airflow]] | [[Comandos Cloud y CLI|CLI]]
